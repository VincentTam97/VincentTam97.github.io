---
layout:     post
title:      一周Papers（3）
subtitle:   2019/3/18 至 2019/3/24
date:       2019-03-24
author:     Vincent Tam
header-img: img/post-190310-1.jpg
catalog: true
tags:
    - Paper
    - NLP
    - Deep Learning
    - Dialogue Generation`
---

## 前言

本周没有什么可以总结的~都关于对话生成，Model & Dataset！



-----



## I Know the Feeling: Learning to Converse with Empathy

### 基本思想

在基于闲聊的对话系统中，如果对话 Agent 能够感知 Speaker 的当前情感状态，并根据这一情感状态来回答 Speaker 的对话，这是我们所希望看到的，就像人与人之间的对话一样。作者为了实现这一目标，考察了当前比较流行的 dataset，发现情感的 label 数量比较少，大部分都是“none”或者“happy”。因此作者提出了他们自己的 dataset/benchmark，并将他们的模型在这一数据集上进行训练和测试，得到了一个相对来说更具有感情的对话 Agent。

### 主要贡献

1. 作者发布了一个创新的情感对话数据集，同时也是一个 benchmark。这个数据集所包含的情感 label 数量很多，可以表达丰富的情感。

	![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190320103545.png)

2. 作者证明，使用这一数据集来训练模型，可以提高端到端的情感对话 Agent 的能力。
3. 我们比较了多个用于进一步提高性能的方法，这些方法整合了不需要繁琐重复训练的表示（representations）。

### 方法介绍

- Speaker & Listener 机制
	先开始一个话题的人，作者将其称为 Speaker，他不仅开启了一个新的对话，并且给这段对话的情感定下了基调。另外一个参与对话的人称为 Listener，他需要了解 Speaker 所构造的对话氛围，并根据这一氛围来选择合适的回答。作者所训练的模型，是站在 Listener 的角度上，考虑如何回答 Speaker 的问题来讨论的。当然，Speaker 所定下的情感基调的 label 信息，不会传给模型，就像真实的人与人之间的对话一样。
	![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190320102719.png)

- Retrieval & Generation
	在 Retrieval 阶段，我们给模型提供一个候选回答集合 Y，期望其能选择一个最佳的回答 y^star^。使用两个基于 Transformer 的 encoder 来表示上下文 x，和候选词 y ∈ Y。
	在 Generation 阶段，使用完整的 Transformer 结构，包含一个 encoder 和一个 decoder。其中 decoder 使用 encoder 的输出来预测 y 的序列结果，我们将其训练为一个最小化目标序列 y^bar^ 的 negative log-likelihood。

	![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190320111951.png)



-----



## Learning Semantic Textual Similarity from Conversations

### 基本思想

作者提出了一种非监督的，基于对话数据的，考虑句子相似性的新方法。作者训练了一个非监督的模型来预测对话中的“input-response”对。由于相似的 question (input) 会得到相似的 response，作者通过学习考虑相似的“input-response”对，来得到相似的 question。作者的模型在 semantic question answering (STS) 和 community question answer (CQA) 的两个 benchmark 中得到了出色的效果。

作者证明了从“input-response”对中学习的 encoder 在句子级语义文本相似性上表现良好。从 Reddit 对话中学到的基本对话模型与 public STS 任务中现有的句子级编码器相比具有竞争力。在 Reddit 和 SNLI 分类上训练的多任务模型在 STS Benchmark 任务上实现了基于句子编码的模型的 SOTA。最后，我们表明，即使没有任何特定任务的训练， Reddit 和 Reddit + SNLI 模型已经在 CQA 子任务 B 上具有竞争力。

### 方法讨论

回答问题，事实上是在多个候选的 response 中选出一个最正确的。在所有候选的 response 中，被选中的 response 作为正例，而其余的 K-1 个 response 则成为反例。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190321185426.png)

假设在训练过程中，一个 batch 内有 K 个“input-response”对，那么训练的细节如下。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190321185731.JPG)

作者考虑了两种 encoder。下图中，两个 encoder 共享参数。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190321191132.png)

作者考虑的 encoder 分别是 DAN (deep averaging network) 和 Transformer encoder。后面的实验显示，使用后者作为模型的 encoder 的效果（precision）更好。使用encoding之后，input 和 response 分别得到了 u 和 v^'^。我们此处使用点积操作，点积的操作是用于衡量 input (u) 对于 response (v) 的一个偏好程度的，即二者的契合程度。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190321190207.JPG)



-----



## [Dataset] MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations

### 基本思想

多模态（Multimodal）数据分析是从多个平行的数据通道中获取信息，从而进行决策的过程。最近已经有一些效果的显著的工作，它们主要考虑利用声音、视觉和文本等多个模态（modalities），来进行多模态的情感识别。然而几乎没有工作去考虑如何理解对话中的情感，一个主要原因就是缺少这方面的一个大的数据集。这篇文章，作者主要扩展和增强了他们的 EmotionLines 数据集，使其不仅仅包含文本对话信息，还有相对应的影像和声音信息。

这篇文章就是围绕着他们的数据集讨论了一下，比较了一下，没有模型和公式什么的。不做详细展开了。



-----



## [Dataset] Training Millions of Personalized Dialogue Agents

### 基本思想

作者希望训练多个，具有不同人格（persona）的对话 Agent。在这篇文章中，作者构造了一个超过500万个人格，超过7亿个对话的数据集，他们利用这一数据集训练端到端的基于 persona 的对话 Agent。实验证明，这个数据集的覆盖面很不错，在这一数据集上进行的预训练，甚至在前人的 PERSONA-CHAT 数据集上达到了 SOTA 的水平。

### 方法介绍

作者想要实现的目标，是基于 input 预测 response，但是要站在某一个人格（persona）的角度来进行预测，并且不要忘记这个系统包含大量的人格。这个人格基于 Context 给出的内容做出 Response。请看以下这个例子：

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190322183111.png)

构建这样一个数据集，作者分为了以下几个步骤。

-	预处理。作者使用了一个已经存在的 REDDIT 社区数据，包含1.7B的评论。他们通过用空格填充所有特殊字符，并在空白字符上拆分来对句子进行标记。他们创建了一个包含250k最常用 token 的字典，并截断了长度超过100个 token 的注释。
-	人格提取。作者将用户所进行的全部的评论，按照一定的规则收集起来，并认为这些评论可以代表一个用户的人格。这些规则包含了对评论的数量和质量的要求。

### 模型介绍

作者构建了一个端到端的对话系统。整个模型一共有三个 encoder，分别是 persona encoder、context encoder 和 response encoder。作者将 encoded context 和  encoded persona 使用一个 1-hop 的带有残差连接的 memory network 结合起来（这个结构需要阅读《Personalizing
dialogue agents: I have a dog, do you have pets too?》这篇文章）。前两个 encoder 共享相同的架构，但参数不同。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190322194259.png)

