---
layout:     post
title:      精读Paper
subtitle:   关于对话系统的 Persona 的一篇重要论述
date:       2019-03-27
author:     Vincent Tam
header-img: img/post-jdpaper.jpg
catalog: true
tags:
    - Paper
    - NLP
    - Deep Learning
    - Dialogue Generation
    - 精读Paper
---



![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190325100307.png)

-----



## 0. 摘要 | Abstract

闲聊对话模型具有以下几个问题：不具备特殊性、不能持续表现出同一种人格、对人缺乏吸引力。在这篇文章所介绍的工作中，作者通过利用用户的个人信息，将闲聊任务变得更具吸引力。作者通过给予对话 Agent 以（1）人格信息，以及收集（2）对话者的信息，来训练模型，最终得到一个更好的对话过程。由于（2）在对话过程中对于 Agent 是未知的，因此作者着力于训练一个能够谈论对话者的个人话题的模型。




## 1. 简介 | Introduction

直到最近，神经网络才具有足够的能力来处理足够大的数据集，从而在闲聊对话中，生成有意义的回答。但是闲聊模型仍然具有这么几种常见的问题：（1）不能持续表现出同一种人格，因为这些模型是通过基于不同的对话者的对话训练而成的；（2）缺少一种详细的长期记忆，因为他们几乎都是为了给出对于最近一段对话的下一句回答训练而成的；（3）很容易生成例如“我不知道”这样的无意义无特殊性回答。这三个问题结合起来，直接使得我们不希望跟对话 Agent 进行互动。作者认为，为了解决这些问题，需要一个更好的数据集。

在这个工作中，作者在构造一个更有吸引力的对话 Agent 这个目标上更进一步，他们赋予 Agent 以一个可配置，但持续的人格（Persona），由多个句子的文本描述来编码，称为 Profile。这个 Profile 可以通过一个记忆增强的神经网络来存储，并用于产生更有个性、更特殊、更持续和迷人的回答。

作者为此构建了 PERSONA-CHAT 数据集，一个全新的，含有162,064个对话的数据集。这个数据集旨在将研究推进至一个，能够缓解传统闲聊机器人所面对的那些问题的新的层次，并希望能通过赋予 Agent 人格的方式，训练出更加具有持续性和吸引力的模型。




## 2. 相关工作 | Related Work

传统的对话系统由多个组件构成，比如对话状态跟踪组件、回答生成器等。它们被用于已经标记好内部对话状态，和已精确定义用户意图的任务中（[Young, 2000](https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2000.0593)）。

最近，端到端的神经网络方法的研究热度不断上涨。有一些较为流行的递归系统，用于生成对话文本，例如 seq2seq（[Sutskever et al., 2014](Sequence to sequence learning with neural networks)；[Vinyals and Le, 2015](A neural conversational model)；[Sordoni et al., 2015](A neural network approach to context-sensitive generation of conversational responses)；[Li et al., 2016b](Deep reinforcement learning for dialogue generation)；[Serban et al.,2017b](A hierarchical latent variable encoder-decoder model for generating dialogues)）。基于 language modeling，这些方法能够依照句法生成连贯新颖的回答，但是由于这些方法是 memory-free 的，因此它们缺少长期的连贯性和持续的人格，就如前面所讨论的一样。一个刚开始发展但还比较有前景的方向是是用一个 memory-augmented 网络来替代（[Sukhbaatar et al., 2015](End-to-end memory networks)；[Dodge et al., 2015](Evaluating prerequisite qualities for learning end-to-end dialog systems)），来提供或学习合适的 memory。

根据这个调查（[Serban et al., 2015](A survey of available corpora for building data-driven dialogue systems)）,“对话系统的人格化是一件重要任务，但暂未得到应有的注意”。在基于目标的对话系统中，有一些工作已经开始着手于让对话 Agent 能够了解对话者的个人信息，并据此调整与其的对话，但是 Agent 不具有自己的人格（[Lucas et al., 2009](Managing speaker identity and user profiles in a spoken dialogue system)；[Joshi et al., 2017](Personalization in goal-oriented dialog)）。对于闲聊系统，最为相关的工作是（[Li et al., 2016a](A persona-based neural conversation model)）。对于 Twitter 语料库中的每个用户，通过分布式嵌入（每个说话者一个）来捕获人物角色以封装诸如背景信息和说话风格之类的个体特征，然后他们使用这些向量来改善他们的 seq2seq 模型的输出，以用于相同的说话者。




## 3. 数据集 | The PERSONA-CHAT Dataset

数据的收集分为三个阶段：
（1）Personas：收集了1155个可取的人格，每一个人格都包含至少5句话来描述其个人信息。还有100个从未见过的人格用于验证，另100个用于测试。
（2）修改后的 Personas：为了避免利用琐碎的单词重叠的建模，我们将相同的1155个人格的其他重写集合众包，其中相关的句子是重新描述，概括或特殊化，使得任务更具挑战性。例如，“我喜欢篮球”可以修改为“我是迈克尔乔丹的忠实粉丝”，不是因为他们的意思相同，而是因为同一种人格可能同时包含两者。修改后的 Persona 如下表所示。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190325163155.png)

（3）Persona 对话：我们将两个众包工作者配对，然后从池中分配一个随机（原始）角色，然后让他们聊天。 这导致在10,907个对话框中有162,064个话语的数据集，其中15,602个话语（1000个对话框）被留出用于验证，并且15024个话语（968个对话框）用于测试。一个对话的范例如下。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190325164050.png)




## 4. 模型 | Models

作者考虑了两种不同的模型：ranking models 和 generative models。前者将训练集中的任意一句对话，都看作是候选的 response，并在其中排序，并选出一个最佳的回答。后者基于对话历史或 persona，逐词生成新的回答。不过，人们仍然可以通过计算生成给定候选者的概率并根据这些分数对候选者进行排名来将后者评估为排名模型。

### 4.1 Baseline ranking models

作者考虑了两种基线模型，一种基于信息检索（IR）的模型（[Sordoni et al., 2015](A neural network approach to context-sensitive generation of conversational responses)），一种有监督的嵌入式模型，Starspace（[Wu et al., 2017](Starspace: Embed all the things!)）。基于 IR 的模型通过在训练集中找到最为相似的对话，作为输出来回答，相似性由 cosine 衡量。Starspace 也是一个基于 IR 的模型，但是通过使用 margin ranking loss 和k-负采样直接针对该任务优化嵌入来学习对话和下一个话语之间的相似性。

### 4.2 Ranking Profile Memory Network

之前的两个模型都通过将其与对话历史相结合来使用 Profile 信息，这意味着这些模型在决定下一个 Utterance 时无法区分这两个模型。在此模型中，作者使用具有对话历史作为输入的记忆网络，然后对 Profile 执行 Attention 以从 Profile 中找到相关线索以与输入组合，然后最终预测下一个话语。作者使用与 Starspace 相同的表示和 loss，二者之间只有是否考虑 Profile 的区别。

如果 Profile 可用，那么注意力将通过这种方式实施：计算输入 q 和 Profile 句子 p~i~ 间的相似性，计算 Softmax 值，然后取加权和。

![1553674973261](C:\Users\62727\AppData\Roaming\Typora\typora-user-images\1553674973261.png)

我们就可以通过排序由 *sim*(q^+^, c^‘^) 计算得到的 c^‘^ ，这称为 1~st~ hop。我们还可以对 Profile 实施多次 Attention 的计算（perform multiple "hops"），而不仅仅是一次，尽管这并未在我们的参数扫描中带来显着增益。

### 4.3 Key-Value Profile Memory Network

此模型对 Key 实施了 Attention。在这个工作中，作者将这个模型应用于对话，将 Key 考虑为对话历史（来自于训练集），将 Value 考虑为下一句 Utterance。这能够使得模型对过去的对话保留记忆，从而能够直接用于改善对下一句对话的预测效果。我们选择的模型与刚刚在 1~st~ hop 中描述的 Profile Memory Network 相同，而在 2~nd~ hop 中，q^+^ 用于参加密钥并输出如前所述的加权值，产生 q^++^，从而可以使用 *sim*(q^++^, c^‘^) 对候选 c^‘^ 进行排名。

由于 (Key-Value) 对的数量可能很多，从而使得训练过程变慢，因此在实验中，作者仅是简单训练了 Profile Memory Network 并使用了相同的权值，而将本模型仅仅用于测试阶段。事实上，直接训练这个模型可能会得到更好的结果，但是与原始网络相比，这种启发式方法已被证明是有益的。

### 4.4 Seq2Seq

输入序列 *x* 通过应用下式来 encode。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190327170744.png)

作者使用 GloVe 来做词向量的嵌入。上式计算的结果（等式左侧的符号）即为最终的 hidden state，将其喂给 decoder *LSTM~dec~* ，作为 decoder 的初始状态 initial state。对于每个时间步 t，decoder 生成单词 j 出现在那个位置的概率，通过 Softmax，如下式。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190327171329.png)

### 4.5 Generative Profile Memory Network

此模型将每一个 Profile 的条目（entry）作为 Memory Network 中独立的记忆表示。跟之前的模型一样，对话历史通过 *LSTM~enc~* 来 encode，其最终的 hidden state 喂给 decoder。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190327174345.png)




## 5. 实验 | Experiments

下面的第一张表显示了使用不同模型进行 Dialog Utterance Prediction 的结果，分别在三种设定下进行：无 Persona、Original Persona 和 修改后的 Persona。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190327175653.png)

下面的第二张表给出了人类对于多个模型的评估结果，同时与人类的表现进行的对比。

![](https://raw.githubusercontent.com/VincentTam97/_BlogImgStorage/master/images/20190327180714.png)



## 6. 总结与讨论 | Conclusion & Discussion

作者相信 PERSONA-CHAT 将成为训练未来对话系统组成部分的有用资源。因为我们已配对人工生成的 Profile 和对话，所以数据有助于构建具有一致个性和观点的 Agent。此外，预测来自对话的 Profile 会在 Goal-Oriented 对话的方向上转移闲聊任务，其具有评价是否成功的指标。我们希望这些数据能够为训练 Agent 提供帮助，训练 Agent 可以提出有关用户 Profile 的问题，记住答案，并在对话中自然地使用它们。